{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function\n",
    "def first_10jobs(url):\n",
    "    # Type th job position and job location\n",
    "    jop=input(\"Enter job position you want to search : \")\n",
    "    jol=input(\"Enter the location for the job : \")\n",
    "    \n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # Entering job position in search option\n",
    "    job_position=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    # clearing the search optin before entering the input\n",
    "    job_position.clear()\n",
    "    # sending the input for job position in search option\n",
    "    job_position.send_keys(jop)\n",
    "\n",
    "    # for job location finding the option and entering the input\n",
    "    job_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    job_location.clear()\n",
    "    job_location.send_keys(jol)\n",
    "\n",
    "    # Now clicking the search button by sending the xpath and click function\n",
    "    search = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "    search.click()\n",
    "    \n",
    "     # creating empty list \n",
    "    job_position=[]\n",
    "    company=[]\n",
    "    experience=[]\n",
    "    location=[]\n",
    "    \n",
    "    # using for loop by sending xpath for finding the job position \n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        job_position.append(i.text)\n",
    "    \n",
    "    # using for loop to find companies by sending xpath for company\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"mt-7 companyInfo subheading lh16\"]'):\n",
    "        if j.text==None:\n",
    "            company.append(None)\n",
    "        else:\n",
    "            company.append(j.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "    # using for loop for finding the experience by sending xpath \n",
    "    for k in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/ul/li[1]/span'):\n",
    "        if  k.text==None:\n",
    "            experience.append(None)\n",
    "        else:\n",
    "            experience.append(k.text)\n",
    "        \n",
    "    # using for loop for finding the job location by sending xpath\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/ul/li[3]/span'):\n",
    "        if l.text==None:\n",
    "            location.append(None)\n",
    "        else:\n",
    "            location.append(l.text)\n",
    "            \n",
    "    # creating data frame \n",
    "    import pandas as pd\n",
    "    analyst_jobs=pd.DataFrame({})\n",
    "    analyst_jobs['Job_Position']=job_position\n",
    "    analyst_jobs['Company']=company\n",
    "    analyst_jobs['Experience']=experience\n",
    "    analyst_jobs['Location']=location\n",
    "    # Limiting only 10 jobs\n",
    "    analyst_jobs=analyst_jobs[:10]\n",
    "\n",
    "    return analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter job position you want to search : Data Analyst \n",
      "Enter the location for the job : Bangalore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials4.1(94 Reviews)</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt L...</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Tata Consultancy Services Ltd.4.0(21115 Reviews)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Shell India Markets Private Limited4.1(623 Rev...</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.4.2(744 Reviews)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.4.2(744 Reviews)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.4.2(744 Reviews)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.4.2(744 Reviews)</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job_Position  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "3  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "4                     Data Analyst - Informatica MDM   \n",
       "5  Assistant Vice President - MIS & Reporting ( B...   \n",
       "6                                       Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                   Applied Materials4.1(94 Reviews)   7-10 Yrs   \n",
       "2  PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt L...    2-4 Yrs   \n",
       "3   Tata Consultancy Services Ltd.4.0(21115 Reviews)    4-9 Yrs   \n",
       "4  Shell India Markets Private Limited4.1(623 Rev...    6-9 Yrs   \n",
       "5  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  12-18 Yrs   \n",
       "6           Myntra Designs Pvt. Ltd.4.2(744 Reviews)    3-6 Yrs   \n",
       "7           Myntra Designs Pvt. Ltd.4.2(744 Reviews)    3-6 Yrs   \n",
       "8           Myntra Designs Pvt. Ltd.4.2(744 Reviews)    4-9 Yrs   \n",
       "9           Myntra Designs Pvt. Ltd.4.2(744 Reviews)    4-8 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                        Mumbai, Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10jobs('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function\n",
    "def datascientist_10jobs(url):\n",
    "    # Type th job position and job location\n",
    "    jop=input(\"Enter job position you want to search : \")\n",
    "    jol=input(\"Enter the location for the job : \")\n",
    "    \n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    # Entering job position in search option\n",
    "    job_position=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    # clearing the search optin before entering the input\n",
    "    job_position.clear()\n",
    "    # sending the input for job position in search option\n",
    "    job_position.send_keys(jop)\n",
    "\n",
    "    # for job location finding the option and entering the input\n",
    "    job_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    job_location.clear()\n",
    "    job_location.send_keys(jol)\n",
    "\n",
    "    # Now clicking the search button by sending the xpath and click function\n",
    "    search = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "    search.click()\n",
    "    \n",
    "     # creating empty list \n",
    "    job_position=[]\n",
    "    company=[]\n",
    "    job_description=[]\n",
    "    location=[]\n",
    "    \n",
    "    # using for loop by sending xpath for finding the job position \n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        job_position.append(i.text)\n",
    "    \n",
    "    # using for loop to find companies by sending xpath for company\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"mt-7 companyInfo subheading lh16\"]'):\n",
    "        if j.text==None:\n",
    "            company.append(None)\n",
    "        else:\n",
    "            company.append(j.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "    # using for loop for finding the job description by sending xpath \n",
    "    for k in driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]'):\n",
    "        if  k.text==None:\n",
    "            job_description.append(None)\n",
    "        else:\n",
    "            job_description.append(k.text)\n",
    "        \n",
    "    # using for loop for finding the job location by sending xpath\n",
    "    for l in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/ul/li[3]/span'):\n",
    "        if l.text==None:\n",
    "            location.append(None)\n",
    "        else:\n",
    "            location.append(l.text)\n",
    "            \n",
    "    # creating data frame \n",
    "    import pandas as pd\n",
    "    datascientist_jobs=pd.DataFrame({})\n",
    "    datascientist_jobs['Job_Position']=job_position\n",
    "    datascientist_jobs['Company']=company\n",
    "    datascientist_jobs['Job_Description']=job_description\n",
    "    datascientist_jobs['Location']=location\n",
    "    # Limiting only 10 jobs\n",
    "    datascientist_jobs=datascientist_jobs[:10]\n",
    "\n",
    "    return datascientist_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter job position you want to search : Data Scientist\n",
      "Enter the location for the job : Bangalore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Position</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Applications invited from all Freshers and exp...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Nielsen3.8(475 Reviews)</td>\n",
       "      <td>Masters degree in Economics, Mathematics, Stat...</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM India Pvt. Limited4.1(9672 Reviews)</td>\n",
       "      <td>Required Technical and Professional ExpertiseP...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited4.1(9672 Reviews)</td>\n",
       "      <td>Should have hired and nurtured talent and grow...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>Responsibilities and duties Focus on developin...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd4.0(248 Reviews)</td>\n",
       "      <td>High motivation, good work ethic and maturityM...</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Philips India Limited4.0(532 Reviews)</td>\n",
       "      <td>Responsibilities and Key Result Areas Design a...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited4.1(9672 Reviews)</td>\n",
       "      <td>modeling and business system design with exper...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Intel Technology India Pvt Ltd4.2(235 Reviews)</td>\n",
       "      <td>Experience in using data analysis techniques a...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd3.7(1322 Revi...</td>\n",
       "      <td>Strong hands-on experience in implementing and...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job_Position  \\\n",
       "0  Data Scientist / Data Analyst -Business Analyst   \n",
       "1                  Senior Data Scientist, Modeling   \n",
       "2                      Data Scientist - IBM Garage   \n",
       "3                                   Data Scientist   \n",
       "4              Senior Data Scientist - Credit risk   \n",
       "5                        Big Data - Data Scientist   \n",
       "6                    Specialist I - Data Scientist   \n",
       "7                                   Data Scientist   \n",
       "8                              Lead Data Scientist   \n",
       "9                       SDE Lead Data Scientist-L3   \n",
       "\n",
       "                                             Company  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                            Nielsen3.8(475 Reviews)   \n",
       "2            IBM India Pvt. Limited4.1(9672 Reviews)   \n",
       "3            IBM India Pvt. Limited4.1(9672 Reviews)   \n",
       "4                                 Scienaptic Systems   \n",
       "5          Xoriant Solutions Pvt Ltd4.0(248 Reviews)   \n",
       "6              Philips India Limited4.0(532 Reviews)   \n",
       "7            IBM India Pvt. Limited4.1(9672 Reviews)   \n",
       "8     Intel Technology India Pvt Ltd4.2(235 Reviews)   \n",
       "9  Huawei Technologies India Pvt Ltd3.7(1322 Revi...   \n",
       "\n",
       "                                     Job_Description  \\\n",
       "0  Applications invited from all Freshers and exp...   \n",
       "1  Masters degree in Economics, Mathematics, Stat...   \n",
       "2  Required Technical and Professional ExpertiseP...   \n",
       "3  Should have hired and nurtured talent and grow...   \n",
       "4  Responsibilities and duties Focus on developin...   \n",
       "5  High motivation, good work ethic and maturityM...   \n",
       "6  Responsibilities and Key Result Areas Design a...   \n",
       "7  modeling and business system design with exper...   \n",
       "8  Experience in using data analysis techniques a...   \n",
       "9  Strong hands-on experience in implementing and...   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...  \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "3  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datascientist_10jobs('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "* You have to use the location and salary filter.\n",
    "* You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "* You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "* The location filter to be used is “Delhi/NCR”\n",
    "* The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to scrape the data naukri.com webpage using some filters\n",
    "def filter_naukri_jobs(url):\n",
    "    \n",
    "    \n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # finding the input location and entering the input for which we want to get data\n",
    "    job_search=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    job_search.clear()\n",
    "    job_search.send_keys(\"data Scientist\")\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Now clicking the search button by sending the xpath and click function\n",
    "    search = driver.find_element_by_xpath('//div[@class=\"search-btn\"]/button')\n",
    "    search.click()\n",
    "\n",
    "    # applying filters for location\n",
    "    for i in driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft\"]'):\n",
    "        if i.text==\"Delhi / NCR\":\n",
    "            i.click()\n",
    "            break\n",
    "    time.sleep(2)        \n",
    "\n",
    "    # applying filters for salary\n",
    "    for j in driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft\"]'):\n",
    "        if j.text==\"3-6 Lakhs\":\n",
    "            j.click()\n",
    "            break\n",
    "    time.sleep(2)\n",
    " \n",
    "    # Create empty list to store scrapped data\n",
    "    job_title=[]\n",
    "    company=[]\n",
    "    job_experience=[]\n",
    "    job_location=[]\n",
    "        \n",
    "    time.sleep(5)\n",
    "    # sending xpath for finding the job title\n",
    "    for header in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        job_title.append(header.text)\n",
    "    # sending xpath for finding company\n",
    "    for comp in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company.append(comp.text)\n",
    "    # sending xpath for finding job experience\n",
    "    for exp in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "        job_experience.append(exp.text)\n",
    "    # sending xpath for finding job location\n",
    "    for loc in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        job_location.append(loc.text)\n",
    "    \n",
    "    # creating dataframe\n",
    "    import pandas as pd\n",
    "    filter_jobs=pd.DataFrame({})\n",
    "    filter_jobs['Job_Title']=job_title\n",
    "    filter_jobs['Company']=company\n",
    "    filter_jobs['Experience']=job_experience\n",
    "    filter_jobs['Location']=job_location\n",
    "   \n",
    "    return filter_jobs           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Biosense Technologies Pvt Ltd</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Thane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Protocol Zone</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sybrant Data</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Global Talent Pool</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Scientist - Process Mining</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Skillsoft</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>placementplanet</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Shadowfax Technologies Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GD Research Center Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst with Power BI , Tableau, Advance ...</td>\n",
       "      <td>EXCELVANA PVT. LTD</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Mumbai, Navi Mumbai, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science Engineer/ML Engineer</td>\n",
       "      <td>MATPLAT</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Freelance | Data Analyst -BioScience</td>\n",
       "      <td>Perfect Digital Media Resources Pvt Ltd</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Chennai(Kilpauk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Engineer - Big Data Engineer</td>\n",
       "      <td>CAIA -Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist Operational Research</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst -BioScience</td>\n",
       "      <td>Perfect Digital Media Resources Pvt Ltd</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Chennai(Kilpauk)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "0                                      Data Scientist   \n",
       "1   Data Scientist - High growth VC backed Influen...   \n",
       "2     Data Scientist / Data Analyst -Business Analyst   \n",
       "3                                      Data Scientist   \n",
       "4                                      Data Scientist   \n",
       "5                                      Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7           Associate Data Scientist - Process Mining   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                    Data Scientist Machine Learning   \n",
       "11                                     Data Scientist   \n",
       "12                                     Data Scientist   \n",
       "13                                     Data Scientist   \n",
       "14  Data Analyst with Power BI , Tableau, Advance ...   \n",
       "15                  Data Science Engineer/ML Engineer   \n",
       "16               Freelance | Data Analyst -BioScience   \n",
       "17                  Data Engineer - Big Data Engineer   \n",
       "18                Data Scientist Operational Research   \n",
       "19                           Data Analyst -BioScience   \n",
       "\n",
       "                                     Company Experience  \\\n",
       "0              Biosense Technologies Pvt Ltd    1-2 Yrs   \n",
       "1            Ravgins International Pvt. Ltd.    3-5 Yrs   \n",
       "2         Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "3                                   Analytos    2-4 Yrs   \n",
       "4                              Protocol Zone    1-4 Yrs   \n",
       "5                               Sybrant Data    2-4 Yrs   \n",
       "6                         Global Talent Pool    2-4 Yrs   \n",
       "7        Shell India Markets Private Limited    3-7 Yrs   \n",
       "8                      Microsoft Corporation    1-2 Yrs   \n",
       "9                                  Skillsoft    1-3 Yrs   \n",
       "10                                 Delhivery    1-3 Yrs   \n",
       "11                           placementplanet    2-3 Yrs   \n",
       "12          Shadowfax Technologies Pvt. Ltd.    1-3 Yrs   \n",
       "13                GD Research Center Pvt Ltd    2-4 Yrs   \n",
       "14                        EXCELVANA PVT. LTD    2-7 Yrs   \n",
       "15                                   MATPLAT    0-5 Yrs   \n",
       "16   Perfect Digital Media Resources Pvt Ltd    1-5 Yrs   \n",
       "17  CAIA -Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "18                                 Delhivery    1-3 Yrs   \n",
       "19   Perfect Digital Media Resources Pvt Ltd    1-5 Yrs   \n",
       "\n",
       "                                             Location  \n",
       "0                                               Thane  \n",
       "1   Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "2   Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "3                                               India  \n",
       "4                                           Ahmedabad  \n",
       "5                                             Chennai  \n",
       "6                                           Bengaluru  \n",
       "7                                             Chennai  \n",
       "8                                           Hyderabad  \n",
       "9                              Hyderabad/Secunderabad  \n",
       "10                                   Gurgaon/Gurugram  \n",
       "11                                          Ahmedabad  \n",
       "12                                   Gurgaon/Gurugram  \n",
       "13                             Hyderabad/Secunderabad  \n",
       "14            Mumbai, Navi Mumbai, Mumbai (All Areas)  \n",
       "15                                Bangalore/Bengaluru  \n",
       "16                                   Chennai(Kilpauk)  \n",
       "17  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...  \n",
       "18                                   Gurgaon/Gurugram  \n",
       "19                                   Chennai(Kilpauk)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_naukri_jobs('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Days_Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansha Solutions</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>3.1</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>13d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Siemens Technology and Services Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Webhelp</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sparkbpl</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Axslogic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           company Ratings Days_Posted\n",
       "0                                          Bechtel     4.0         15d\n",
       "1                         Lantern Digital Services     3.7          6d\n",
       "2                                 Mansha Solutions     4.1          8d\n",
       "3                                  Priority Vendor     3.1         12d\n",
       "4                                         Ericsson     4.1         13d\n",
       "5                             Gauge Data Solutions     4.3         12d\n",
       "6  Siemens Technology and Services Private Limited     4.1         24h\n",
       "7                                          Webhelp     3.8          5d\n",
       "8                                         Sparkbpl     5.0         12d\n",
       "9                                         Axslogic     4.0         10d"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//div[@class=\"d-flex\"]/button').click()\n",
    "\n",
    "email=driver.find_element_by_xpath('//input[@id=\"userEmail\"]')\n",
    "email.send_keys(\"asheemsiwach.66199.maeco@gmail.com\")\n",
    "\n",
    "password=driver.find_element_by_xpath('//input[@id=\"userPassword\"]')\n",
    "password.send_keys(\"abcdefghijkl0123\")\n",
    "\n",
    "sign_in=driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath(\"//button[@data-test='search-bar-submit']\").click()\n",
    "time.sleep(5)\n",
    "\n",
    "company=[]\n",
    "days_ago=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")[:10]:\n",
    "    if i.text==None:\n",
    "        ratings.append(\"None\")\n",
    "    else:\n",
    "        ratings.append(i.text)\n",
    "driver.implicitly_wait(10)\n",
    "for c in driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a/span\")[:10]:\n",
    "    company.append(c.text)\n",
    "driver.implicitly_wait(10)\n",
    "for d in driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")[:10]:\n",
    "    days_ago.append(d.text)\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "glassdoor_jobs=pd.DataFrame({})\n",
    "glassdoor_jobs['company']=company[:10]\n",
    "glassdoor_jobs['Ratings']=ratings[:10]\n",
    "glassdoor_jobs['Days_Posted']=days_ago[:10]\n",
    "\n",
    "glassdoor_jobs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function for finding salaries of different companies from glassdoor website\n",
    "\n",
    "def salaries(url):\n",
    "    \n",
    "    # inputs for the data\n",
    "    job=input(\"Enter the job title : \")\n",
    "    location=input(\"Enter location for job : \")\n",
    "    \n",
    "    # Load the driver and get url\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    # maximizing window\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    # Searching the location for input and sending the input\n",
    "    search_job=driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]').send_keys(job)\n",
    "    search_location=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]').send_keys(Keys.CONTROL+\"a\")\n",
    "    search_location=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]').send_keys(Keys.BACKSPACE)\n",
    "    search_location=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]').send_keys(location)\n",
    "    \n",
    "    # by sending xpath for search option, submitting the result\n",
    "    search=driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # creating empty lists\n",
    "    companies=[]\n",
    "    average_salary=[]\n",
    "    min_salary=[]\n",
    "    max_salary=[]\n",
    "    \n",
    "    # applying forloops for finding the desired resutl\n",
    "    # by using xpath finding the companies name\n",
    "    for company in driver.find_elements_by_xpath('//div[@class=\"d-flex\"]/div[2]/p[2]')[:10]:\n",
    "        companies.append(company.text)\n",
    "    # by using xpath finding the average salary   \n",
    "    for average in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]')[:10]:\n",
    "        average_salary.append(average.text)\n",
    "        \n",
    "    # by using xpath finding the minimum salary\n",
    "    for minimum in driver.find_elements_by_xpath('//div[@class=\"col-3 offset-1 d-none d-md-block\"]/div/div[2]/span[1]')[:10]: \n",
    "        min_salary.append(minimum.text)\n",
    "    # by using xpath finding maximum salary\n",
    "    for maximum in driver.find_elements_by_xpath('//div[@class=\"col-3 offset-1 d-none d-md-block\"]/div/div[2]/span[2]')[:10]:\n",
    "        max_salary.append(maximum.text)\n",
    "    \n",
    "    time.sleep(2)   \n",
    "    \n",
    "    # creating dataframe of scrapped data\n",
    "    import pandas as pd\n",
    "    glassdoor_salaries=pd.DataFrame({})\n",
    "    glassdoor_salaries['Company']=companies\n",
    "    glassdoor_salaries['Average Salary']=average_salary\n",
    "    glassdoor_salaries['Minimum Salary']=min_salary\n",
    "    glassdoor_salaries['Maximum Salary']=max_salary\n",
    "\n",
    "    return glassdoor_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job title : Data Scientist\n",
      "Enter location for job : Noida\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,11,228\\n/yr</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>₹1,095K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533\\n/yr</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 8,97,795\\n/yr</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057\\n/yr</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781\\n/yr</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142\\n/yr</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192\\n/yr</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221\\n/yr</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243\\n/yr</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 14,13,288\\n/yr</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company    Average Salary Minimum Salary Maximum Salary\n",
       "0  Tata Consultancy Services   ₹ 6,11,228\\n/yr          ₹343K        ₹1,095K\n",
       "1                  Accenture  ₹ 11,46,533\\n/yr          ₹577K        ₹2,213K\n",
       "2                        IBM   ₹ 8,97,795\\n/yr          ₹586K        ₹2,730K\n",
       "3         Ericsson-Worldwide   ₹ 7,38,057\\n/yr          ₹355K        ₹1,613K\n",
       "4                  Delhivery  ₹ 12,39,781\\n/yr          ₹450K       ₹11,622K\n",
       "5         UnitedHealth Group  ₹ 13,36,142\\n/yr        ₹1,069K        ₹1,520K\n",
       "6         Valiance Solutions   ₹ 8,15,192\\n/yr          ₹502K        ₹1,465K\n",
       "7              ZS Associates  ₹ 11,35,221\\n/yr          ₹202K        ₹1,809K\n",
       "8                EXL Service  ₹ 11,44,243\\n/yr          ₹575K        ₹1,520K\n",
       "9     Optum Global Solutions  ₹ 14,13,288\\n/yr        ₹1,014K        ₹2,149K"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to scrap the data of 100 sunglasses from flipkart\n",
    "def sunglasses_listing(url):\n",
    "    \n",
    "    \n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    # by sending url getting webpage permission\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    # Before entering the output removing the login option\n",
    "    without_login=driver.find_element_by_xpath('//div[@class=\"_2QfC02\"]/button')\n",
    "    without_login.click()\n",
    "    # maximizing window\n",
    "    driver.maximize_window()\n",
    "     \n",
    "    # finding the input option and clearing it and then sending the input we want\n",
    "    search=driver.find_element_by_class_name(\"_3704LK\")\n",
    "    search.clear()\n",
    "    search.send_keys(\"sunglasses\")\n",
    "    time.sleep(3 )\n",
    "    # finding and clicking the search button\n",
    "    searching=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]') \n",
    "    searching.click()\n",
    "    \n",
    "    # creating empty list for saving data \n",
    "    brands=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "\n",
    "    # applying forloop for scrapping data from many pages\n",
    "    start_page=0\n",
    "    end_page=3\n",
    "    for page in range(start_page,end_page+1):\n",
    "        time.sleep(3)\n",
    "        # sending xpath for finding the brand name\n",
    "        for brand in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "            brands.append(brand.text)\n",
    "        # sending xpath for finding the product description\n",
    "        for product in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):\n",
    "            if driver.find_element_by_xpath('//a[@class=\"IRpwTa\"]')==None:\n",
    "                product_desc.append(\"NA\")\n",
    "            else:\n",
    "                product_desc.append(product.text)\n",
    "        # sending xpath for finding the price of product\n",
    "        for p in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "            price.append(p.text)\n",
    "        # sending xpath for finding discount on product\n",
    "        for dis in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "            discount.append(dis.text)\n",
    "       \n",
    "        # Applying if else conditon to go to next page\n",
    "        if page==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        else:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"][2]').click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # creating dataframe\n",
    "    import pandas as pd\n",
    "    sunglasses=pd.DataFrame({})\n",
    "    sunglasses['Brand']=brands[:100]\n",
    "    sunglasses['product_description']=product_desc[:100]\n",
    "    sunglasses['Price']=price[:100]\n",
    "    sunglasses['Discount']=discount[:100]\n",
    "\n",
    "    return sunglasses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection, Riding Glasses, Others Aviator,...</td>\n",
       "      <td>₹209</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round, Shield Sunglass...</td>\n",
       "      <td>₹395</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹359</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹759</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹1,115</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹224</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Night Vision, Gradient, Mirrore...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                product_description   Price  \\\n",
       "0     Singco India  UV Protection, Riding Glasses, Others Aviator,...    ₹209   \n",
       "1           AISLIN  UV Protection, Gradient Round, Shield Sunglass...    ₹395   \n",
       "2         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹630   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "4   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)    ₹499   \n",
       "..             ...                                                ...     ...   \n",
       "95          GANSTA  UV Protection, Polarized Wayfarer Sunglasses (56)    ₹359   \n",
       "96        Fastrack              UV Protection Aviator Sunglasses (58)    ₹759   \n",
       "97        Fastrack   UV Protection, Mirrored Wayfarer Sunglasses (53)  ₹1,115   \n",
       "98          GANSTA            Mirrored Aviator Sunglasses (Free Size)    ₹224   \n",
       "99       ROYAL SON  UV Protection, Night Vision, Gradient, Mirrore...    ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   70% off  \n",
       "1   77% off  \n",
       "2   21% off  \n",
       "3   15% off  \n",
       "4   77% off  \n",
       "..      ...  \n",
       "95  82% off  \n",
       "96  15% off  \n",
       "97  14% off  \n",
       "98  77% off  \n",
       "99  73% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses_listing('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. \n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function\n",
    "\n",
    "def reviews(url):\n",
    "    # Loading driver and url\n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    # goint to the review's webpage\n",
    "    driver.find_element_by_xpath('//div[@class=\"col JOpGWq\"]/a').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Creating empty lists\n",
    "    ratings=[]\n",
    "    title=[]\n",
    "    reviews=[]\n",
    "\n",
    "    start_page=0\n",
    "    end_page=10\n",
    "    driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[11]').click()\n",
    "    for page in range(start_page,end_page+1):\n",
    "        time.sleep(2)\n",
    "        # by using xpath finding titles\n",
    "        for t in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "            title.append(t.text)\n",
    "        # By using xpath finding reviews\n",
    "        for rev in driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]/div[2]/div/div'):\n",
    "            reviews.append(rev.text)\n",
    "        # by using xpath finding ratings\n",
    "        for r in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "            ratings.append(r.text)\n",
    "        time.sleep(2)    \n",
    "    \n",
    "        # if else conditions for going to next page    \n",
    "        if page ==0:\n",
    "            a=driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[11]').click()\n",
    "            driver.implicitly_wait(10)    \n",
    "        else:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "    \n",
    "        time.sleep(2)\n",
    "        \n",
    "        \n",
    "    # Creating dataframe\n",
    "    import pandas as pd\n",
    "    iphone_reviews=pd.DataFrame({})\n",
    "    iphone_reviews['ratings']=ratings[:100]\n",
    "    iphone_reviews['title']=title[:100]\n",
    "    iphone_reviews['reviews']=reviews[:100]\n",
    "\n",
    "    return iphone_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>title</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>awesome Phone Smooth Touch Too good Sexyy look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Product is nice at the deviled time the delive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Absolutely powerful gadget. Loved it’s look! S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings                  title  \\\n",
       "0        5              Brilliant   \n",
       "1        5       Perfect product!   \n",
       "2        5          Great product   \n",
       "3        5      Worth every penny   \n",
       "4        4            Good choice   \n",
       "..     ...                    ...   \n",
       "95       5  Mind-blowing purchase   \n",
       "96       5              Fabulous!   \n",
       "97       5              Fabulous!   \n",
       "98       5              Excellent   \n",
       "99       4  Mind-blowing purchase   \n",
       "\n",
       "                                              reviews  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  awesome Phone Smooth Touch Too good Sexyy look...  \n",
       "96  I purchased the iPhone 11 a month back. I must...  \n",
       "97  Product is nice at the deviled time the delive...  \n",
       "98  Just go for it.\\nThis phone is really amazing....  \n",
       "99  Absolutely powerful gadget. Loved it’s look! S...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_reviews=reviews(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\")\n",
    "iphone_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to scrap the data of 100 sneakers from flipkart\n",
    "def sneakers_listing(url):\n",
    "    \n",
    "    \n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    # by sending url getting webpage permission\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    # Before entering the output removing the login option\n",
    "    without_login=driver.find_element_by_xpath('//div[@class=\"_2QfC02\"]/button')\n",
    "    without_login.click()\n",
    "    # maximizing window\n",
    "    driver.maximize_window()\n",
    "     \n",
    "    # finding the input option and clearing it and then sending the input we want\n",
    "    search=driver.find_element_by_class_name(\"_3704LK\")\n",
    "    search.clear()\n",
    "    search.send_keys(\"sneakers\")\n",
    "    time.sleep(3 )\n",
    "    # finding and clicking the search button\n",
    "    searching=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]') \n",
    "    searching.click()\n",
    "    \n",
    "    # creating empty list for saving data \n",
    "    brands=[]\n",
    "    product_desc=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "\n",
    "    # applying forloop for scrapping data from many pages\n",
    "    start_page=0\n",
    "    end_page=3\n",
    "    for page in range(start_page,end_page+1):\n",
    "        time.sleep(3)\n",
    "        # sending xpath for finding the brand name\n",
    "        for brand in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "            brands.append(brand.text)\n",
    "        # sending xpath for finding the product description\n",
    "        for product in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):\n",
    "            if driver.find_element_by_xpath('//a[@class=\"IRpwTa\"]')==None:\n",
    "                product_desc.append(\"NA\")\n",
    "            else:\n",
    "                product_desc.append(product.text)\n",
    "        # sending xpath for finding the price of product\n",
    "        for p in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "            price.append(p.text)\n",
    "        # sending xpath for finding discount on product\n",
    "        for dis in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "            discount.append(dis.text)\n",
    "       \n",
    "        # Applying if else conditon to go to next page\n",
    "        if page==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        else:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"][2]').click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # creating dataframe\n",
    "    import pandas as pd\n",
    "    sneakers=pd.DataFrame({})\n",
    "    sneakers['Brand']=brands[:100]\n",
    "    sneakers['product_description']=product_desc[:100]\n",
    "    sneakers['Price']=price[:100]\n",
    "    sneakers['Discount']=discount[:100]\n",
    "\n",
    "    return sneakers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEVI'S</td>\n",
       "      <td>Basic 2.0 Sneakers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>Colourblocked Trending Multicolor Ultralight c...</td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹283</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Fashionable casual sneakers shoes Sneakers For...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>5001 Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Englewood</td>\n",
       "      <td>Puma Wired Cage Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ESSENCE</td>\n",
       "      <td>Men Sports Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>30% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Aircum</td>\n",
       "      <td>AART CORE Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                product_description   Price  \\\n",
       "0         LEVI'S                         Basic 2.0 Sneakers For Men  ₹1,499   \n",
       "1          oxpeo  Colourblocked Trending Multicolor Ultralight c...    ₹419   \n",
       "2   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men    ₹379   \n",
       "3        Numenzo                                   Sneakers For Men    ₹398   \n",
       "4       HOTSTYLE                          Sneakers Sneakers For Men    ₹283   \n",
       "..           ...                                                ...     ...   \n",
       "95       Numenzo  Fashionable casual sneakers shoes Sneakers For...    ₹599   \n",
       "96     bluemaker                              5001 Sneakers For Men    ₹474   \n",
       "97     Englewood                   Puma Wired Cage Sneakers For Men    ₹499   \n",
       "98       ESSENCE                        Men Sports Sneakers For Men    ₹449   \n",
       "99        Aircum                         AART CORE Sneakers For Men    ₹474   \n",
       "\n",
       "   Discount  \n",
       "0   50% off  \n",
       "1   58% off  \n",
       "2   62% off  \n",
       "3   60% off  \n",
       "4   43% off  \n",
       "..      ...  \n",
       "95  66% off  \n",
       "96  55% off  \n",
       "97  68% off  \n",
       "98  30% off  \n",
       "99  63% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers_listing('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”.And then scrape First 100 shoes data you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for scrapping the data using filters\n",
    "def filter_shoes(url):\n",
    "    \n",
    "    # Loading the drivers and url\n",
    "    driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # by using xpath selecting color filter for scrapping desired data \n",
    "    if driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]') != None:\n",
    "        driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(2)\n",
    "    # by using the xpath selecting price filter\n",
    "    if driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]') != None:\n",
    "        driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    # creating empty list for storing scrapped data\n",
    "    brands=[]\n",
    "    short_description=[]\n",
    "    prices=[]\n",
    "\n",
    "    count=0\n",
    "    while count <2:\n",
    "        # using for loop finding the brands naem for shoes\n",
    "        for brand in driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]/h3'):\n",
    "            brands.append(brand.text)\n",
    "        # Using for loop findig short description of shoes \n",
    "        for desc in driver.find_elements_by_xpath('//div[@class=\"product-productMetaInfo\"]/h4[1]'):\n",
    "            short_description.append(desc.text)\n",
    "        # using for loop finding the price of shoes    \n",
    "        for price in driver.find_elements_by_xpath('//div[@class=\"product-price\"]/span[1]'):\n",
    "\n",
    "            try:\n",
    "                prices.append(price.text)\n",
    "            except NoSuchElementException:\n",
    "                prices.append(driver.find_element_by_xpath('//span[@class=\"product-strike\"]').text)\n",
    "    \n",
    "        # by using xpath moving to next page for more data  \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "        count+=1   \n",
    "\n",
    "    # Creating dataframe\n",
    "    import pandas as pd\n",
    "    shoes=pd.DataFrame({})\n",
    "    shoes['Brand_Name']=brands[:100]\n",
    "    shoes['Product_Description']=short_description[:100]\n",
    "    shoes['Product_Price']=prices[:100]\n",
    " \n",
    "    return shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Product_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7721Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 10846Rs. 15495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged RC Sportstyle Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Rogue 2 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe OIL SLK</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Textured Derbys</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand_Name             Product_Description       Product_Price\n",
       "0              Nike     Men JORDAN DELTA Basketball           Rs. 12495\n",
       "1              Nike    Men KD13 EP Basketball Shoes           Rs. 12995\n",
       "2   PUMA Motorsport   Unisex Mercedes Running Shoes            Rs. 7999\n",
       "3              Nike    Women AIR ZOOM Running Shoes   Rs. 7721Rs. 10295\n",
       "4              Nike      Men React Infinity Running  Rs. 10846Rs. 15495\n",
       "..              ...                             ...                 ...\n",
       "94             Nike     Women AIR MAX VIVA Sneakers           Rs. 12495\n",
       "95     UNDER ARMOUR  Charged RC Sportstyle Sneakers            Rs. 8999\n",
       "96     UNDER ARMOUR   Charged Rogue 2 Running Shoes            Rs. 7999\n",
       "97     UNDER ARMOUR   Women Charged Breathe OIL SLK            Rs. 8999\n",
       "98            Ruosh             Men Textured Derbys            Rs. 8990\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myntra_shoes=filter_shoes(\"https://www.myntra.com/shoes\")\n",
    "myntra_shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laptop(url):\n",
    "    \n",
    "    #load the drivers and URL\n",
    "    driver = webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #create empty list for storing the data\n",
    "    item_title=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "    \n",
    "    #search for laptop product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "        \n",
    "    #apply filter for \"Intel Core i7\"\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #apply filter for \"Intel Core i9\"  \n",
    "    \n",
    "        \n",
    "    #scrape the data\n",
    "    for view in driver.find_elements_by_xpath('//div[@class=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20\"]'):\n",
    "        titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "        for i in titles:\n",
    "            item_title.append(i.text)\n",
    "        item_title=item_title\n",
    "        prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "        for i in prices:\n",
    "            try:\n",
    "                price.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                price.append(\"Not Available\")\n",
    "        price=price      \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "        for i in ratings:\n",
    "            try:\n",
    "                rating.append(i.get_attribute('aria-label'))\n",
    "            except NoSuchElementException:\n",
    "                rating.append(\"Not Avialable\")\n",
    "        rating=rating     \n",
    "        \n",
    "    time.sleep(2)\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"filters\"]/ul[1]/li[1]/span/a/span[2]').click()\n",
    "    time.sleep(5)\n",
    "    driver.implicitly_wait(10)\n",
    "     \n",
    "    try:    \n",
    "        driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598162031\"]/span/a').click()\n",
    "    except NoSuchElementException as NV:\n",
    "        print(NV)\n",
    "    \n",
    "        \n",
    "        \n",
    "    #create a DataFrame for our data\n",
    "    amazon_laptops=pd.DataFrame({})\n",
    "    amazon_laptops['Title']=item_title[:50]\n",
    "    amazon_laptops['Price']=price[:50]\n",
    "    amazon_laptops['Rating']=rating[:50]\n",
    "    return amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@id=\"p_n_feature_thirteen_browse-bin/12598162031\"]/span/a\"}\n",
      "  (Session info: chrome=90.0.4430.212)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>53,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>3,43,099</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) HP 840g2 Elitebook Laptop ( Intel Co...</td>\n",
       "      <td>53,990</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>33,990</td>\n",
       "      <td>2.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>83,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>2,01,524</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019 HP 17.3\" HD+ Touchscreen Laptop Computer</td>\n",
       "      <td>1,34,999</td>\n",
       "      <td>1.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>1,17,999</td>\n",
       "      <td>2.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dell Inspiron 7306 i7 11th Gen, x360 13.3\" 4K ...</td>\n",
       "      <td>33,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>91,490</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...</td>\n",
       "      <td>79,980</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>78,593</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>3,05,701</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>97,990</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Razer Blade Pro 17 Gaming Laptop 2019</td>\n",
       "      <td>99,999</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...</td>\n",
       "      <td>85,990</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MSI Prestige 14Evo A11M-492IN 14\" FHD Gaming L...</td>\n",
       "      <td>46,290</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>91,499</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>69,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>39,999</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...</td>\n",
       "      <td>39,999</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Renewed) Lenovo T430 14-inch Laptop (Core i7/...</td>\n",
       "      <td>53,999</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(Renewed) Dell Intel 4th Gen Core i7 4600U 14-...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>2.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>3,43,099</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>53,990</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>89,990</td>\n",
       "      <td>1.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(Renewed) HP 840g2 Elitebook Laptop ( Intel Co...</td>\n",
       "      <td>33,990</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...</td>\n",
       "      <td>83,990</td>\n",
       "      <td>2.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>2,01,524</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>1,34,999</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019 HP 17.3\" HD+ Touchscreen Laptop Computer</td>\n",
       "      <td>1,17,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...</td>\n",
       "      <td>33,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>91,490</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Dell Inspiron 7306 i7 11th Gen, x360 13.3\" 4K ...</td>\n",
       "      <td>79,980</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>78,593</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...</td>\n",
       "      <td>3,05,701</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>97,990</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>99,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>85,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Razer Blade Pro 17 Gaming Laptop 2019</td>\n",
       "      <td>46,290</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...</td>\n",
       "      <td>91,499</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>MSI Prestige 14Evo A11M-492IN 14\" FHD Gaming L...</td>\n",
       "      <td>69,990</td>\n",
       "      <td>2.6 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>39,999</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>39,999</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>53,999</td>\n",
       "      <td>1.9 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...</td>\n",
       "      <td>1,35,490</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title     Price  \\\n",
       "0   Mi Notebook Horizon Edition 14 Intel Core i5-1...    53,999   \n",
       "1   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  1,35,490   \n",
       "2   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  3,43,099   \n",
       "3   (Renewed) HP 840g2 Elitebook Laptop ( Intel Co...    53,990   \n",
       "4   Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...    89,990   \n",
       "5   HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...    33,990   \n",
       "6   Life Digital Laptop 15.6-inch (39.62 cms) (Int...    83,990   \n",
       "7   Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...  2,01,524   \n",
       "8       2019 HP 17.3\" HD+ Touchscreen Laptop Computer  1,34,999   \n",
       "9   OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...    36,990   \n",
       "10  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  1,17,999   \n",
       "11  Dell Inspiron 7306 i7 11th Gen, x360 13.3\" 4K ...    33,990   \n",
       "12  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    91,490   \n",
       "13  Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...    79,980   \n",
       "14  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    78,593   \n",
       "15  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...  3,05,701   \n",
       "16  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    97,990   \n",
       "17              Razer Blade Pro 17 Gaming Laptop 2019    99,999   \n",
       "18  Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...    85,990   \n",
       "19  MSI Prestige 14Evo A11M-492IN 14\" FHD Gaming L...    46,290   \n",
       "20  Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...    91,499   \n",
       "21  (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...    69,990   \n",
       "22  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    39,999   \n",
       "23  Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...    39,999   \n",
       "24  (Renewed) Lenovo T430 14-inch Laptop (Core i7/...    53,999   \n",
       "25  (Renewed) Dell Intel 4th Gen Core i7 4600U 14-...  1,35,490   \n",
       "26  Mi Notebook Horizon Edition 14 Intel Core i5-1...  3,43,099   \n",
       "27  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...    53,990   \n",
       "28  Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...    89,990   \n",
       "29  (Renewed) HP 840g2 Elitebook Laptop ( Intel Co...    33,990   \n",
       "30  Lenovo Ideapad 720s Intel Core i7 8th Gen 13.3...    83,990   \n",
       "31  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...  2,01,524   \n",
       "32  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  1,34,999   \n",
       "33  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    36,990   \n",
       "34      2019 HP 17.3\" HD+ Touchscreen Laptop Computer  1,17,999   \n",
       "35  OMEN by HP 15.6-inch 10th Gen Intel Core i7-10...    33,990   \n",
       "36  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    91,490   \n",
       "37  Dell Inspiron 7306 i7 11th Gen, x360 13.3\" 4K ...    79,980   \n",
       "38  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    78,593   \n",
       "39  Acer Swift 5 14\" (35.56cms) Full HD IPS Displa...  3,05,701   \n",
       "40  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    97,990   \n",
       "41  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    99,999   \n",
       "42  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    85,990   \n",
       "43              Razer Blade Pro 17 Gaming Laptop 2019    46,290   \n",
       "44  Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...    91,499   \n",
       "45  MSI Prestige 14Evo A11M-492IN 14\" FHD Gaming L...    69,990   \n",
       "46  Dell Inspiron 5406 14\" FHD Touch Display 2in1 ...    39,999   \n",
       "47  (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...    39,999   \n",
       "48  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    53,999   \n",
       "49  Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...  1,35,490   \n",
       "\n",
       "                Rating  \n",
       "0   4.4 out of 5 stars  \n",
       "1   4.3 out of 5 stars  \n",
       "2   4.0 out of 5 stars  \n",
       "3   3.1 out of 5 stars  \n",
       "4   4.7 out of 5 stars  \n",
       "5   2.6 out of 5 stars  \n",
       "6   4.0 out of 5 stars  \n",
       "7   4.5 out of 5 stars  \n",
       "8   1.9 out of 5 stars  \n",
       "9   3.1 out of 5 stars  \n",
       "10  2.6 out of 5 stars  \n",
       "11  4.1 out of 5 stars  \n",
       "12  4.4 out of 5 stars  \n",
       "13  3.6 out of 5 stars  \n",
       "14  4.2 out of 5 stars  \n",
       "15  4.3 out of 5 stars  \n",
       "16  3.0 out of 5 stars  \n",
       "17  3.0 out of 5 stars  \n",
       "18  3.0 out of 5 stars  \n",
       "19  3.0 out of 5 stars  \n",
       "20  4.4 out of 5 stars  \n",
       "21  4.3 out of 5 stars  \n",
       "22  4.0 out of 5 stars  \n",
       "23  3.1 out of 5 stars  \n",
       "24  4.7 out of 5 stars  \n",
       "25  2.6 out of 5 stars  \n",
       "26  4.0 out of 5 stars  \n",
       "27  4.5 out of 5 stars  \n",
       "28  1.9 out of 5 stars  \n",
       "29  3.1 out of 5 stars  \n",
       "30  2.6 out of 5 stars  \n",
       "31  4.1 out of 5 stars  \n",
       "32  4.4 out of 5 stars  \n",
       "33  3.6 out of 5 stars  \n",
       "34  4.2 out of 5 stars  \n",
       "35  4.3 out of 5 stars  \n",
       "36  3.0 out of 5 stars  \n",
       "37  3.0 out of 5 stars  \n",
       "38  3.0 out of 5 stars  \n",
       "39  3.0 out of 5 stars  \n",
       "40  4.4 out of 5 stars  \n",
       "41  4.3 out of 5 stars  \n",
       "42  4.0 out of 5 stars  \n",
       "43  3.1 out of 5 stars  \n",
       "44  4.7 out of 5 stars  \n",
       "45  2.6 out of 5 stars  \n",
       "46  4.0 out of 5 stars  \n",
       "47  4.5 out of 5 stars  \n",
       "48  1.9 out of 5 stars  \n",
       "49  3.1 out of 5 stars  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop('https://www.amazon.in/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
