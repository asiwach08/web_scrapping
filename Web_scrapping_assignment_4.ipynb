{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using driver and url for opening the url page\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "# maximising the window and waiting driver to open browser\n",
    "driver.maximize_window()\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# using the url \n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "# sending command to wait as driver needs time to load page\n",
    "time.sleep(5)\n",
    "\n",
    "# using window scrolling to scroll page down to see the desired data to scrap\n",
    "for i in range(0,15):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "\n",
    "# create empty lists to store the data to be scraped\n",
    "rank =[]\n",
    "name =[]\n",
    "artist =[]\n",
    "upload =[]\n",
    "views =[]\n",
    "\n",
    "# using forloops for finding the data\n",
    "# by providing xpath and then using text finding the data\n",
    "\n",
    "# Rank of videos\n",
    "RANKS=driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[1]')\n",
    "for i in RANKS:\n",
    "    rank.append(i.text.replace(\".\",\"\"))\n",
    "\n",
    "# name of video\n",
    "NAME=driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[2]')\n",
    "for i in NAME:\n",
    "    name.append(i.text.replace('\"',\"\").split(\"[\")[0])\n",
    "\n",
    "# artist/uploader who uploaded the video\n",
    "ARTIST=driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[3]')\n",
    "for i in ARTIST:\n",
    "    artist.append(i.text)\n",
    "\n",
    "# upload date of video\n",
    "UPLOAD=driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[5]')\n",
    "for i in UPLOAD:\n",
    "    upload.append(i.text)\n",
    "\n",
    "# views on video\n",
    "VIEWS=driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr/td[4]')\n",
    "for i in VIEWS:\n",
    "    views.append(i.text)\n",
    "    \n",
    "# after scraping the data we need to store it in a format using pandas dataframe \n",
    "import pandas as pd\n",
    "# setting dataframe name and then adding data by limiting the index of 30 videos\n",
    "youtube =pd.DataFrame({'Ranking':rank[:30], 'Video_name':name[:30], 'Uploader':artist[:30], \n",
    "                       'Upload_Date':upload[:30], 'Views(billions)':views[:30]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Video_name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views(billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking                                 Video_name  \\\n",
       "0        1                           Baby Shark Dance   \n",
       "1        2                                  Despacito   \n",
       "2        3                       Johny Johny Yes Papa   \n",
       "3        4                               Shape of You   \n",
       "4        5                              See You Again   \n",
       "5        6   Masha and the Bear – Recipe for Disaster   \n",
       "6        7                                Uptown Funk   \n",
       "7        8  Learning Colors – Colorful Eggs on a Farm   \n",
       "8        9                                  Bath Song   \n",
       "9       10                              Gangnam Style   \n",
       "10      11                Phonics Song with Two Words   \n",
       "11      12                                      Sugar   \n",
       "12      13                                      Sorry   \n",
       "13      14                             Dame Tu Cosita   \n",
       "14      15                                       Roar   \n",
       "15      16                             Counting Stars   \n",
       "16      17                          Thinking Out Loud   \n",
       "17      18                                 Dark Horse   \n",
       "18      19                                      Faded   \n",
       "19      20                               Shake It Off   \n",
       "20      21                          Wheels on the Bus   \n",
       "21      22                                    Lean On   \n",
       "22      23                                   Bailando   \n",
       "23      24                             Girls Like You   \n",
       "24      25                                 Let Her Go   \n",
       "25      26                                   Mi Gente   \n",
       "26      27                                    Perfect   \n",
       "27      28                                      Hello   \n",
       "28      29           Waka Waka (This Time for Africa)   \n",
       "29      30                                     Axel F   \n",
       "\n",
       "                          Uploader        Upload_Date Views(billions)  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016            8.71  \n",
       "1                       Luis Fonsi   January 12, 2017            7.38  \n",
       "2                      LooLoo Kids    October 8, 2016            5.41  \n",
       "3                       Ed Sheeran   January 30, 2017            5.34  \n",
       "4                      Wiz Khalifa      April 6, 2015            5.13  \n",
       "5                       Get Movies   January 31, 2012            4.44  \n",
       "6                      Mark Ronson  November 19, 2014            4.19  \n",
       "7                      Miroshka TV  February 27, 2018            4.12  \n",
       "8       Cocomelon – Nursery Rhymes        May 2, 2018            4.10  \n",
       "9                              Psy      July 15, 2012            4.08  \n",
       "10                       ChuChu TV      March 6, 2014            3.90  \n",
       "11                        Maroon 5   January 14, 2015            3.48  \n",
       "12                   Justin Bieber   October 22, 2015            3.44  \n",
       "13                       El Chombo      April 5, 2018            3.37  \n",
       "14                      Katy Perry  September 5, 2013            3.36  \n",
       "15                     OneRepublic       May 31, 2013            3.31  \n",
       "16                      Ed Sheeran    October 7, 2014            3.26  \n",
       "17                      Katy Perry  February 20, 2014            3.08  \n",
       "18                     Alan Walker   December 3, 2015            3.07  \n",
       "19                    Taylor Swift    August 18, 2014            3.06  \n",
       "20      Cocomelon – Nursery Rhymes       May 24, 2018            3.05  \n",
       "21                     Major Lazer     March 22, 2015            3.04  \n",
       "22                Enrique Iglesias     April 11, 2014            3.04  \n",
       "23                        Maroon 5       May 31, 2018            3.04  \n",
       "24                       Passenger      July 25, 2012            3.00  \n",
       "25                        J Balvin      June 29, 2017            2.92  \n",
       "26                      Ed Sheeran   November 9, 2017            2.86  \n",
       "27                           Adele   October 22, 2015            2.84  \n",
       "28                         Shakira       June 4, 2010            2.84  \n",
       "29                      Crazy Frog      June 16, 2009            2.82  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the scraped data of top viewed videos on youtube\n",
    "youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n",
    "\n",
    "# using the navigation bar,go to fixtures option from international navigation option\n",
    "international_fixtures=driver.find_element_by_xpath('//li[@class=\"drop-down__option  \"]/a').get_attribute('href')\n",
    "driver.get(international_fixtures)\n",
    "time.sleep(5)\n",
    "\n",
    "# create empty list to store data\n",
    "match,series,place,date,Time = [],[],[],[],[]\n",
    "\n",
    "# using for-loops for scraping the data for each empty list\n",
    "# scraping the match title\n",
    "MATCHES =driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]')\n",
    "for i in MATCHES:\n",
    "    match.append(i.text)\n",
    "    \n",
    "#scraping the series    \n",
    "SERIES =driver.find_elements_by_xpath('//div[@class=\"fixture__format-strip\"]/span[2]')\n",
    "for i in SERIES:\n",
    "    series.append(i.text)\n",
    "    \n",
    "# scraping the location of match   \n",
    "PLACES =driver.find_elements_by_xpath('//div[@class=\"fixture__description u-unskewed-text\"]/p/span')\n",
    "for i in PLACES:\n",
    "    place.append(i.text)\n",
    "\n",
    "# scraping the day,day number,month,time using differnet xpaths and then concating them in a list\n",
    "DAY =driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/span')\n",
    "DAY_NO =driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/span')\n",
    "MONTH =driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/div/span[1]')\n",
    "TIME =driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/div/span[2]')\n",
    "for i in range(len(DAY)):\n",
    "    date.append(DAY[i].text+\",\"+DAY_NO[i].text+\" \"+MONTH[i].text.lower()+\" 2021\")\n",
    "    Time.append(TIME[i].text)\n",
    "    \n",
    "# after scraping, by using above lists creating a dataframe of all data\n",
    "import pandas as pd\n",
    "india_fixtures=pd.DataFrame({\"Match_Title\":match,\"Series\":series,\"Place\":place,\n",
    "                             \"Date\":date,\"Time\":Time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>Friday,18 june 2021</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday,04 august 2021</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday,12 august 2021</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday,25 august 2021</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday,02 september 2021</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday,10 september 2021</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                       Series                        Place  \\\n",
       "0       Final  ICC WORLD TEST CHAMPIONSHIP  The Ageas Bowl, Southampton   \n",
       "1    1st Test         ENGLAND V INDIA 2021     Trent Bridge, Nottingham   \n",
       "2    2nd Test         ENGLAND V INDIA 2021               Lord's, London   \n",
       "3    3rd Test         ENGLAND V INDIA 2021            Headingley, Leeds   \n",
       "4    4th Test         ENGLAND V INDIA 2021             The Oval, London   \n",
       "5    5th Test         ENGLAND V INDIA 2021     Old Trafford, Manchester   \n",
       "\n",
       "                         Date       Time  \n",
       "0         Friday,18 june 2021  15:00 IST  \n",
       "1    Wednesday,04 august 2021  15:30 IST  \n",
       "2     Thursday,12 august 2021  15:30 IST  \n",
       "3    Wednesday,25 august 2021  15:30 IST  \n",
       "4  Thursday,02 september 2021  15:30 IST  \n",
       "5    Friday,10 september 2021  15:30 IST  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the scraped datea of India's international fixtures\n",
    "india_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "driver.get('https://www.guru99.com/')\n",
    "# waiting for 5 sec to load url\n",
    "time.sleep(5)\n",
    "\n",
    "# using xpath,click on url for selenium tutorials page\n",
    "driver.find_element_by_xpath('//div[@class=\"srch\"]/span[8]/a').click()\n",
    "time.sleep(5)\n",
    "\n",
    "# using xpath click on new url for selenium exception handling page\n",
    "driver.find_element_by_xpath('//table[@class=\"table\"]/tbody/tr[34]/td/a').click()\n",
    "\n",
    "# create empty lists to store the data\n",
    "name        =[]\n",
    "description =[]\n",
    "\n",
    "# storing xpaths in variables (exceptions and descriptions) to scrap data from them\n",
    "# scrape the exception name\n",
    "exceptions=driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[1]')\n",
    "\n",
    "# scrape the description\n",
    "descriptions =driver.find_elements_by_xpath('//table[@class=\"table table-striped\"]/tbody/tr/td[2]')\n",
    "\n",
    "# now using for-loop on both the variables and append values of both in the empty list \n",
    "for i in range(len(exceptions)):\n",
    "    name.append(exceptions[i].text)\n",
    "    description.append(descriptions[i].text)\n",
    "\n",
    "# importing pandas to form a dataframe of scraped data using both lists\n",
    "import pandas as pd\n",
    "selenium_exceptions =pd.DataFrame({\"Exception Name\":name[1:],\"Description\":description[1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of selenium exception handlings\n",
    "selenium_exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "driver.get('http://statisticstimes.com/')\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# go to the nav bar economy option and click on drop down button\n",
    "driver.find_element_by_xpath('//div[@class=\"navbar\"]/div[2]/button').click()\n",
    "time.sleep(3)\n",
    "# go to the new url of India economy present in Eonomic drop down option\n",
    "driver.find_element_by_xpath('//div[@class=\"navbar\"]/div[2]/div/a[3]').click()\n",
    "time.sleep(3)\n",
    "# by giving xpath of state wise gdp of india move to another url\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    " \n",
    "time.sleep(3)\n",
    "# scroll down the page to the table\n",
    "for i in range(0,18):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "    \n",
    "# create empty list to store data\n",
    "rank =[]                             # rank of state based on gdp\n",
    "state =[]                            # state's name\n",
    "state_gdp_2018_to_2019 =[]           # gdp of state from 2018 to 2019\n",
    "state_gdp_2019_to_2020 =[]           # gdp of state from 2019 to 2020\n",
    "share_2018_to_2019 =[]               # share of state in gdp in year(2018-2019)\n",
    "gdp =[]                              # gdp of state\n",
    "\n",
    "\n",
    "# assigning diff. variables to webelements so that we can scrap data into above lists\n",
    "RANKS =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[1]')\n",
    "STATE =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[2]')\n",
    "STATE_GDP_2018_TO_2019 =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[4]')\n",
    "STATE_GDP_2019_TO_2020 =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[3]')\n",
    "SHARE_2018_TO_2019 =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[5]')\n",
    "GDP =driver.find_elements_by_xpath('//div[@id=\"table_id_wrapper\"]/table/tbody/tr/td[6]')\n",
    "\n",
    "# using for-loop on each variables assigned and then appending data into lists\n",
    "for i in range(len(RANKS)):\n",
    "    rank.append(RANKS[i].text)\n",
    "    state.append(STATE[i].text)\n",
    "    state_gdp_2018_to_2019.append(STATE_GDP_2018_TO_2019[i].text)\n",
    "    state_gdp_2019_to_2020.append(STATE_GDP_2019_TO_2020[i].text)\n",
    "    share_2018_to_2019.append(SHARE_2018_TO_2019[i].text)\n",
    "    gdp.append(GDP[i].text)\n",
    "    \n",
    "# importing pandas and creating dataframe of above lists\n",
    "import pandas as pd\n",
    "state_gdp =pd.DataFrame({\"Rank\":rank, \"State\":state, \"GSDP(18-19)\":state_gdp_2018_to_2019,\n",
    "                         \"GSDP(19-20)\":state_gdp_2019_to_2020, \"Share(18-19)\":share_2018_to_2019,\n",
    "                         \"GDP($ billion)\":gdp })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State_wise_gross_domestic_product_of_India -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(19-20) Share(18-19)  \\\n",
       "0     1                Maharashtra   2,632,792           -       13.94%   \n",
       "1     2                 Tamil Nadu   1,630,208   1,845,853        8.63%   \n",
       "2     3              Uttar Pradesh   1,584,764   1,687,818        8.39%   \n",
       "3     4                    Gujarat   1,502,899           -        7.96%   \n",
       "4     5                  Karnataka   1,493,127   1,631,977        7.91%   \n",
       "5     6                West Bengal   1,089,898   1,253,832        5.77%   \n",
       "6     7                  Rajasthan     942,586   1,020,989        4.99%   \n",
       "7     8             Andhra Pradesh     862,957     972,782        4.57%   \n",
       "8     9                  Telangana     861,031     969,604        4.56%   \n",
       "9    10             Madhya Pradesh     809,592     906,672        4.29%   \n",
       "10   11                     Kerala     781,653           -        4.14%   \n",
       "11   12                      Delhi     774,870     856,112        4.10%   \n",
       "12   13                    Haryana     734,163     831,610        3.89%   \n",
       "13   14                      Bihar     530,363     611,804        2.81%   \n",
       "14   15                     Punjab     526,376     574,760        2.79%   \n",
       "15   16                     Odisha     487,805     521,275        2.58%   \n",
       "16   17                      Assam     315,881           -        1.67%   \n",
       "17   18               Chhattisgarh     304,063     329,180        1.61%   \n",
       "18   19                  Jharkhand     297,204     328,598        1.57%   \n",
       "19   20                Uttarakhand     245,895           -        1.30%   \n",
       "20   21            Jammu & Kashmir     155,956           -        0.83%   \n",
       "21   22           Himachal Pradesh     153,845     165,472        0.81%   \n",
       "22   23                        Goa      73,170      80,449        0.39%   \n",
       "23   24                    Tripura      49,845      55,984        0.26%   \n",
       "24   25                 Chandigarh      42,114           -        0.22%   \n",
       "25   26                 Puducherry      34,433      38,253        0.18%   \n",
       "26   27                  Meghalaya      33,481      36,572        0.18%   \n",
       "27   28                     Sikkim      28,723      32,496        0.15%   \n",
       "28   29                    Manipur      27,870      31,790        0.15%   \n",
       "29   30                   Nagaland      27,283           -        0.14%   \n",
       "30   31          Arunachal Pradesh      24,603           -        0.13%   \n",
       "31   32                    Mizoram      22,287      26,503        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of state wise gross domestic product of India\n",
    "print(\"State_wise_gross_domestic_product_of_India -\")\n",
    "state_gdp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "driver.get('https://github.com/')\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# go to the trending page using xpath \n",
    "trending=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a').get_attribute('href')\n",
    "driver.get(trending)\n",
    "\n",
    "# create empty lists\n",
    "repositories=[]     # repository titles\n",
    "description=[]      # repository discription\n",
    "languages=[]        # languages used in repository\n",
    "contributors=[]     # count of contributors present in repository\n",
    "\n",
    "# using beautiful soup fetching the data for repository title,description and languages\n",
    "soup1=BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "# applying for loop to scrap repository title\n",
    "for i in soup1.find_all('span',class_=\"text-normal\"):\n",
    "    if i.text !=\"→\":\n",
    "        repositories.append(i.text.strip().replace(\" /\",\"\"))\n",
    "# scraping description       \n",
    "for d in soup1.find_all('p',class_=\"col-9 color-text-secondary my-1 pr-4\"):\n",
    "    try:\n",
    "        description.append(d.text.strip())\n",
    "    except NoSuchElementException:           # using exception if no such element present \n",
    "        description.append(None)\n",
    "# scraping languages        \n",
    "for l in soup1.find_all('span',class_=\"d-inline-block ml-0 mr-3\"):\n",
    "    try:\n",
    "        languages.append(l.text.replace(\"\\n\",\"\"))\n",
    "    except NoSuchElementException:\n",
    "        languages.append(None)\n",
    "\n",
    "# create empty list to store urls\n",
    "repo_urls=[]\n",
    "\n",
    "# now contributors data not present on same page.So fetching urls of repositores \n",
    "repository_urls=driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in repository_urls:\n",
    "    repo_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "# now using for-loop  scraping contributors data from each url\n",
    "for url in repo_urls:\n",
    "    driver.get(url)\n",
    "    \n",
    "    diff_links=driver.find_elements_by_xpath('//h2[@class=\"h4 mb-3\"]/a')\n",
    "    for i in diff_links:\n",
    "        count=i.get_attribute(\"href\")\n",
    "        if \"contributors\" in count:\n",
    "            try:contributors.append(i.text.split()[1]) \n",
    "            except NoSuchElementException:\n",
    "                contributors.append(\"NA\")\n",
    "                \n",
    "# creating dataframe using above lists \n",
    "github = pd.DataFrame({\"Repository Title\":repositories[:20],\"Repository Description\":description[:20]\n",
    "                      ,\"Contributors Count\":contributors[:20],\"Language Used\":languages[:20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trending github repositories :-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jina-ai</td>\n",
       "      <td>An easier way to build neural search on the cloud</td>\n",
       "      <td>97</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willmcgugan</td>\n",
       "      <td>Rich is a Python library for rich text and bea...</td>\n",
       "      <td>90</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monyhar</td>\n",
       "      <td>梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...</td>\n",
       "      <td>198</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>programthink</td>\n",
       "      <td>【编程随想】收藏的电子书清单（多个学科，含下载链接）</td>\n",
       "      <td>164</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jwasham</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>357</td>\n",
       "      <td>Haskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>streamich</td>\n",
       "      <td>React Hooks — 👍</td>\n",
       "      <td>8</td>\n",
       "      <td>AGS Script</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hasura</td>\n",
       "      <td>Blazing fast, instant realtime GraphQL APIs on...</td>\n",
       "      <td>13</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>walidshaari</td>\n",
       "      <td>Curated resources help you prepare for the CNC...</td>\n",
       "      <td>83</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>siduck76</td>\n",
       "      <td>beautiful neovim setup configured in lua</td>\n",
       "      <td>159</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>trimstray</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>2</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lydiahallie</td>\n",
       "      <td>A long list of (advanced) JavaScript questions...</td>\n",
       "      <td>800</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IlanKalendarov</td>\n",
       "      <td>Bitcoin Core integration/staging tree</td>\n",
       "      <td>230</td>\n",
       "      <td>Vim script</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SuMaiKaDe</td>\n",
       "      <td>A new type of shell</td>\n",
       "      <td>669</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td>4</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nushell</td>\n",
       "      <td>Generate obfuscated meterpreter shells</td>\n",
       "      <td>286</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neovim</td>\n",
       "      <td>iOS 14.5 WebKit/Safari based Jailbreak</td>\n",
       "      <td>676</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smokeme</td>\n",
       "      <td>ripgrep recursively searches directories for a...</td>\n",
       "      <td>312</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RPwnage</td>\n",
       "      <td>Your window into the Elastic Stack</td>\n",
       "      <td>479</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BurntSushi</td>\n",
       "      <td>This is a simple backtesting framework to help...</td>\n",
       "      <td>355</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>elastic</td>\n",
       "      <td>A powerful JavaScript library for interacting ...</td>\n",
       "      <td>18</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repository Title                             Repository Description  \\\n",
       "0           jina-ai  An easier way to build neural search on the cloud   \n",
       "1       willmcgugan  Rich is a Python library for rich text and bea...   \n",
       "2           monyhar  梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...   \n",
       "3      programthink                         【编程随想】收藏的电子书清单（多个学科，含下载链接）   \n",
       "4           jwasham  A complete computer science study plan to beco...   \n",
       "5         streamich                                    React Hooks — 👍   \n",
       "6            hasura  Blazing fast, instant realtime GraphQL APIs on...   \n",
       "7       walidshaari  Curated resources help you prepare for the CNC...   \n",
       "8          siduck76           beautiful neovim setup configured in lua   \n",
       "9         trimstray  A collection of inspiring lists, manuals, chea...   \n",
       "10      lydiahallie  A long list of (advanced) JavaScript questions...   \n",
       "11   IlanKalendarov              Bitcoin Core integration/staging tree   \n",
       "12        SuMaiKaDe                                A new type of shell   \n",
       "13          bitcoin    Vim-fork focused on extensibility and usability   \n",
       "14          nushell             Generate obfuscated meterpreter shells   \n",
       "15           neovim             iOS 14.5 WebKit/Safari based Jailbreak   \n",
       "16          smokeme  ripgrep recursively searches directories for a...   \n",
       "17          RPwnage                 Your window into the Elastic Stack   \n",
       "18       BurntSushi  This is a simple backtesting framework to help...   \n",
       "19          elastic  A powerful JavaScript library for interacting ...   \n",
       "\n",
       "   Contributors Count Language Used  \n",
       "0                  97        Python  \n",
       "1                  90        Python  \n",
       "2                 198             C  \n",
       "3                 164    TypeScript  \n",
       "4                 357       Haskell  \n",
       "5                   8    AGS Script  \n",
       "6                  13           Lua  \n",
       "7                  83            C#  \n",
       "8                 159        Python  \n",
       "9                   2           C++  \n",
       "10                800          Rust  \n",
       "11                230    Vim script  \n",
       "12                669        Python  \n",
       "13                  4    JavaScript  \n",
       "14                286          Rust  \n",
       "15                676    TypeScript  \n",
       "16                312        Python  \n",
       "17                479    JavaScript  \n",
       "18                355    JavaScript  \n",
       "19                 18            Go  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's check the scraped data\n",
    "print(\"Top trending github repositories :-\")\n",
    "github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "url='https://www.billboard.com/'\n",
    "driver.get(url)\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# from navigation bar go to charts\n",
    "charts=driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[1]/div[1]/ul/li[1]/a').get_attribute('href')\n",
    "driver.get(charts)\n",
    "\n",
    "# now go to the hot100 option\n",
    "hot100=driver.find_element_by_xpath('//*[@id=\"main\"]/div[2]/div/div[1]/a').get_attribute('href')\n",
    "driver.get(hot100)\n",
    "\n",
    "# create empty lists \n",
    "song =[]          # name of song\n",
    "artist =[]        # artist of song\n",
    "week_rank =[]     # last week rank of song\n",
    "peak_rank =[]     # peak rank of song\n",
    "board_weeks =[]   # weeks on chart\n",
    "\n",
    "# Using xpath for finding the location of data we needed and then storing in list\n",
    "# scraping the song name\n",
    "SONG_NAME =driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]')\n",
    "for name in SONG_NAME:\n",
    "    song.append(name.text)\n",
    "    \n",
    "# scraping artist's name\n",
    "ARTIST_NAME=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "for art in ARTIST_NAME:\n",
    "    artist.append(art.text)\n",
    "\n",
    "# scraping last week rank\n",
    "WEEK_RANK=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "for last in WEEK_RANK:\n",
    "    week_rank.append(last.text)\n",
    "    \n",
    "# scraping the peek week\n",
    "PEAK_RANK=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "for peak in PEAK_RANK:\n",
    "    peak_rank.append(peak.text)\n",
    "    \n",
    "# scraping the weeks on chart\n",
    "BOARD_WEEK =PEAK_RANK=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "for board in BOARD_WEEK:\n",
    "    board_weeks.append(board.text)\n",
    "    \n",
    "# creating dataframe using above lists\n",
    "hot_100_songs= pd.DataFrame({\"Song Name\":song, \"Artist Name\":artist, \"Last Week Rank\":week_rank,\n",
    "                            \"Peak Week\":peak_rank, \"Weeks on board\":board_weeks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of top 100 songs :-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Week</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>87</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hold On</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>86</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wasted On You</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Outside</td>\n",
       "      <td>MO3 X OG Bobby Billions</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Botella Tras Botella</td>\n",
       "      <td>Gera MX + Christian Nodal</td>\n",
       "      <td>-</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song Name                               Artist Name  \\\n",
       "0                 Butter                                       BTS   \n",
       "1               Good 4 U                            Olivia Rodrigo   \n",
       "2             Levitating                 Dua Lipa Featuring DaBaby   \n",
       "3    Leave The Door Open  Silk Sonic (Bruno Mars & Anderson .Paak)   \n",
       "4        Save Your Tears                The Weeknd & Ariana Grande   \n",
       "..                   ...                                       ...   \n",
       "95     All I Know So Far                                      P!nk   \n",
       "96               Hold On                             Justin Bieber   \n",
       "97         Wasted On You                             Morgan Wallen   \n",
       "98               Outside                   MO3 X OG Bobby Billions   \n",
       "99  Botella Tras Botella                 Gera MX + Christian Nodal   \n",
       "\n",
       "   Last Week Rank Peak Week Weeks on board  \n",
       "0               1         1              2  \n",
       "1               2         1              3  \n",
       "2               4         2             35  \n",
       "3               5         1             13  \n",
       "4               7         1             25  \n",
       "..            ...       ...            ...  \n",
       "95             87        74              3  \n",
       "96             86        20             13  \n",
       "97             98         9             19  \n",
       "98              -        99              1  \n",
       "99              -        60              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check scraped data of top 100 songs\n",
    "print(\"Details of top 100 songs :-\")\n",
    "hot_100_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "driver.get('https://www.naukri.com/')\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# navigate through recruiters and go to the new url of recruiters\n",
    "recruiters=driver.find_element_by_xpath('//a[@title=\"Search Recruiters\"]').get_attribute('href')\n",
    "driver.get(recruiters)\n",
    "\n",
    "# go to search field and add the input we want to search\n",
    "search =driver.find_element_by_class_name(\"sugInp\")    # search input area\n",
    "search.send_keys(\"Data Science\")                       # entering our input in search option\n",
    "time.sleep(3)                                          # waiting for few seconds for the result sugg.\n",
    "search.send_keys(Keys.ENTER)                           # for search result,using enter key \n",
    "\n",
    "# listing all the urls in which desired data is present\n",
    "urls =[]\n",
    "for i in range(1,118):\n",
    "    urls.append('https://www.naukri.com/data-science-recruiters-{}'.format(i))\n",
    "    \n",
    "name =[]\n",
    "designation =[]\n",
    "company =[]\n",
    "skills =[]\n",
    "location =[]\n",
    "\n",
    "# using listed urls for getting the data by applying for-loops\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    # scraping names of recruiters\n",
    "    NAMES =driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]')\n",
    "    for i in NAMES:\n",
    "        name.append(i.text)\n",
    "    # scraping designation of recruiters\n",
    "    DESIGNATION =driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]')\n",
    "    for i in DESIGNATION:\n",
    "        designation.append(i.text)\n",
    "    # scraping recruiters company name\n",
    "    COMPANY =driver.find_elements_by_xpath('//a[@class=\"ellipsis\"][2]')\n",
    "    for i in COMPANY:\n",
    "        company.append(i.text)\n",
    "    # scraping skills mentioned by recruiters for getting hired\n",
    "    SKILLS =driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in SKILLS:\n",
    "        skills.append(i.text)\n",
    "    # scraping the location\n",
    "    LOCATION =driver.find_elements_by_xpath('//small[@class=\"ellipsis\"]')\n",
    "    for i in LOCATION:\n",
    "        try:location.append(i.text)\n",
    "        except NoSuchElementException:\n",
    "            location.append(\"NA\")\n",
    "            \n",
    "# create dataframe using the above list\n",
    "recruiters =pd.DataFrame({\"Name\":name[:5700], \"Designation\":designation[:5700], \"Company\":company[:5700],\n",
    "                          \"Skills they hire for\":skills[:5700], \"Location\":location[:5700]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of datascience recruiters form Nokri.com :-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>Kalpashree</td>\n",
       "      <td>Human Resource Executive</td>\n",
       "      <td>Integra Micro Software Services (P) Ltd.</td>\n",
       "      <td>Java, .Net, Node JS, PHP, Angular JS, BDE, Sal...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>Ronak Doshi</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>IMPERIA LIFE SCIENCES PRIVATE LIMITED</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>Harpreet singh</td>\n",
       "      <td>Manager</td>\n",
       "      <td>BDS recruitment Private Limited</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>mounika sagar</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>OMICS INTERNATIONAL PRIVATE LIMITED</td>\n",
       "      <td>Editing, Journal, Pharmacy</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>Rupali Paul</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Incedo</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name               Designation  \\\n",
       "0                 Aakash Harit                HR Manager   \n",
       "1         shravan Kumar Gaddam         Company Recruiter   \n",
       "2     MARSIAN Technologies LLP                Company HR   \n",
       "3                 Anik Agrawal         Company Recruiter   \n",
       "4                 subhas patel               Founder CEO   \n",
       "...                        ...                       ...   \n",
       "5695                Kalpashree  Human Resource Executive   \n",
       "5696               Ronak Doshi         Company Recruiter   \n",
       "5697            Harpreet singh                   Manager   \n",
       "5698             mounika sagar         Company Recruiter   \n",
       "5699               Rupali Paul              HR Recruiter   \n",
       "\n",
       "                                       Company  \\\n",
       "0                         Data Science Network   \n",
       "1                Shore Infotech India Pvt. Ltd   \n",
       "2                     MARSIAN Technologies LLP   \n",
       "3        Enerlytics Software Solutions Pvt Ltd   \n",
       "4                              LibraryXProject   \n",
       "...                                        ...   \n",
       "5695  Integra Micro Software Services (P) Ltd.   \n",
       "5696     IMPERIA LIFE SCIENCES PRIVATE LIMITED   \n",
       "5697           BDS recruitment Private Limited   \n",
       "5698       OMICS INTERNATIONAL PRIVATE LIMITED   \n",
       "5699                                    Incedo   \n",
       "\n",
       "                                   Skills they hire for  \\\n",
       "0     Classic ASP Developer, Internet Marketing Prof...   \n",
       "1     .Net, Java, Data Science, Linux Administration...   \n",
       "2     Data Science, Artificial Intelligence, Machine...   \n",
       "3     Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4     Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "...                                                 ...   \n",
       "5695  Java, .Net, Node JS, PHP, Angular JS, BDE, Sal...   \n",
       "5696                                      Not Specified   \n",
       "5697                                      Not Specified   \n",
       "5698                         Editing, Journal, Pharmacy   \n",
       "5699                                      Not Specified   \n",
       "\n",
       "                      Location  \n",
       "0                        Delhi  \n",
       "1     Hyderabad / Secunderabad  \n",
       "2                         Pune  \n",
       "3                    Ahmedabad  \n",
       "4                UK - (london)  \n",
       "...                        ...  \n",
       "5695                     Noida  \n",
       "5696     Bengaluru / Bangalore  \n",
       "5697     Bengaluru / Bangalore  \n",
       "5698  Hyderabad / Secunderabad  \n",
       "5699                      Pune  \n",
       "\n",
       "[5700 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of recruiters\n",
    "print(\"Details of datascience recruiters form Nokri.com :-\")\n",
    "recruiters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# scroll down the page to the table\n",
    "for i in range(0,21):\n",
    "    driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "\n",
    "# create empty lists to store data\n",
    "book_name =[]      # name of book\n",
    "author =[]         # author's name\n",
    "sales =[]          # sales of book\n",
    "publisher =[]      # publisher of book\n",
    "genre =[]          # genre of book\n",
    "\n",
    "# scraping the book name or title\n",
    "BOOKS= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for i in BOOKS:\n",
    "    book_name.append(i.text)\n",
    "\n",
    "# scraping the authors of book\n",
    "AUTHORS= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for a in AUTHORS:\n",
    "    author.append(a.text)\n",
    "    \n",
    "# scraping the sale of book    \n",
    "SALES= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for sale in SALES:\n",
    "    sales.append(sale.text)\n",
    "\n",
    "# scraping the publisher of book\n",
    "PUBLISHERS= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for p in PUBLISHERS:\n",
    "    publisher.append(p.text)\n",
    "\n",
    "# scraping genre of book\n",
    "GENRE= driver.find_elements_by_xpath('//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for g in GENRE:\n",
    "    genre.append(g.text)\n",
    "\n",
    "# import pandas and creating dataframe using above list to present data\n",
    "import pandas as pd\n",
    "novels = pd.DataFrame({\"Title\":book_name, \"Author\":author, \"Volume Sales\":sales,\n",
    "                       \"Publisher\":publisher, \"Genre\":genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of Highest selling novels -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of highest selling novels \n",
    "print(\"Details of Highest selling novels -\")\n",
    "Highest_selling_novels=novels\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# create empty list to store data\n",
    "name =[]          # name of series/show\n",
    "year_span =[]     # year span of series\n",
    "genre =[]         # genre of series\n",
    "runtime =[]       # runtime of series\n",
    "ratings =[]       # ratings of series\n",
    "votes =[]         # votes for the series\n",
    "\n",
    "# Using xpath for finding the location of data we needed and then storing in list\n",
    "# scraping the name of series\n",
    "NAMES =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/a')\n",
    "for n in NAMES:\n",
    "    name.append(n.text)\n",
    "\n",
    "# scraping the year span of series\n",
    "YEAR_SPAN =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/h3/SPAN[2]')\n",
    "for year in YEAR_SPAN:\n",
    "    year_span.append(year.text.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "\n",
    "# scraping the genre of series\n",
    "GENRE =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "for g in GENRE:\n",
    "    genre.append(g.text)\n",
    "\n",
    "# scraping the runtime\n",
    "RUNTIME =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p/span[3]')\n",
    "for run in RUNTIME:\n",
    "    runtime.append(run.text)\n",
    "\n",
    "# scraping the ratings\n",
    "RATINGS =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/div/div/span[2]')\n",
    "for r in RATINGS:\n",
    "    ratings.append(r.text)\n",
    "\n",
    "# scraping the votes given to series\n",
    "VOTES =driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for v in VOTES:\n",
    "    votes.append(v.text)\n",
    "       \n",
    "# import pandas and create dataframe using above lists\n",
    "import pandas as pd\n",
    "tv_series =pd.DataFrame({\"Name\":name, \"Year Span\":year_span, \"Genre\":genre, \"Run time\":runtime, \n",
    "                        \"Ratings\":ratings, \"Votes\":votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most watched tv series data from imdb.com -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,820,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>861,581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>873,460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>223,608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005–2020</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>190,945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name  Year Span                     Genre  \\\n",
       "0                  Game of Thrones  2011–2019  Action, Adventure, Drama   \n",
       "1                  Stranger Things     2016–     Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  2010–2022   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  2017–2020  Drama, Mystery, Thriller   \n",
       "4                          The 100  2014–2020    Drama, Mystery, Sci-Fi   \n",
       "..                             ...        ...                       ...   \n",
       "95                           Reign  2013–2017            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  2017–2019  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  2005–2020     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  2015–2019      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       2018    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.3  1,820,074  \n",
       "1    51 min     8.7    861,581  \n",
       "2    44 min     8.2    873,460  \n",
       "3    60 min     7.6    262,315  \n",
       "4    43 min     7.6    223,608  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,517  \n",
       "96   50 min     7.8     54,999  \n",
       "97   42 min       8    167,254  \n",
       "98   45 min     7.1     34,834  \n",
       "99  572 min     8.6    190,945  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of most watched tv series\n",
    "print(\"Most watched tv series data from imdb.com -\")\n",
    "tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate and load chrome browser\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# load the url\n",
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)\n",
    "# waiting for driver 10 sec to load url\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a').click()\n",
    "\n",
    "# create empty lists to store data\n",
    "dataset =[]         # name of dataset\n",
    "data_type =[]       # data type present in dataset i.e univariate,bivariate or multivariate\n",
    "task =[]            # default task to be used in dataset\n",
    "attribute_type=[]   # types of variables/attributes present in dataset i.e integer,real,categorical\n",
    "no_instances =[]    # no. of records/rows data\n",
    "no_attributes =[]   # no. of variables/columns present\n",
    "year =[]            # year in which data published\n",
    "\n",
    "# Using xpath for finding the location of data we needed and then storing in list\n",
    "# scraping the dataset name\n",
    "DATASET=driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[1]')\n",
    "for data in DATASET:\n",
    "    dataset.append(data.text.replace(\" \",\"\"))\n",
    "    \n",
    "# scraping data type\n",
    "DATA_TYPE =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[2]')\n",
    "for dtype in DATA_TYPE:\n",
    "    data_type.append(dtype.text.replace(\" \",\"\"))\n",
    "\n",
    "# scraping the default task\n",
    "TASK =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[3]')\n",
    "for t in TASK:\n",
    "    task.append(t.text.replace(\" \",\"\"))\n",
    "    \n",
    "# scraping attribute types\n",
    "ATTRIBUTE_TYPE =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[4]')\n",
    "for a in ATTRIBUTE_TYPE:\n",
    "    attribute_type.append(a.text.replace(\" \",\"\"))\n",
    "    \n",
    "# scraping no. of instances\n",
    "NO_INSTANCES =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[5]')\n",
    "for instance in NO_INSTANCES:\n",
    "    no_instances.append(instance.text.replace(\" \",\"\"))\n",
    "    \n",
    "# scraping no. of attributes\n",
    "NO_ATTRIBUTES =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[6]')\n",
    "for attribute in NO_ATTRIBUTES:\n",
    "    no_attributes.append(attribute.text.replace(\" \",\"\"))\n",
    "    \n",
    "# scraping the year data published\n",
    "YEAR =driver.find_elements_by_xpath('//table[@border=\"1\"]/tbody/tr/td[7]')\n",
    "for y in YEAR:\n",
    "    year.append(y.text.replace(\" \",\"\"))\n",
    "    \n",
    "# importing pandas and creating dataframe using above lists\n",
    "import pandas as pd\n",
    "uci_repository =pd.DataFrame({\"Dataset Name\":dataset[1:], \"Data Type\":data_type[1:],\n",
    "                              \"Task\":task[1:], \"Attribute Type\":attribute_type[1:], \n",
    "                              \"No_of_instances\":no_instances[1:],\"No_of_attributes\":no_attributes[1:],\n",
    "                              \"Year\":year[1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI Machine Learning Repository :-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical,Integer,Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical,Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical,Integer,Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnonymousMicrosoftWebData</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical,Integer,Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehiclecouponrecommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>GaitClassification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>WikipediaMathEssentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>WikipediaMathEssentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>SynchronousMachineDataSet</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Dataset Name     Data Type                 Task  \\\n",
       "0                           Abalone  Multivariate       Classification   \n",
       "1                             Adult  Multivariate       Classification   \n",
       "2                         Annealing  Multivariate       Classification   \n",
       "3         AnonymousMicrosoftWebData                Recommender-Systems   \n",
       "4                        Arrhythmia  Multivariate       Classification   \n",
       "..                              ...           ...                  ...   \n",
       "583  in-vehiclecouponrecommendation  Multivariate       Classification   \n",
       "584              GaitClassification  Multivariate       Classification   \n",
       "585         WikipediaMathEssentials   Time-Series           Regression   \n",
       "586         WikipediaMathEssentials   Time-Series           Regression   \n",
       "587       SynchronousMachineDataSet  Multivariate           Regression   \n",
       "\n",
       "               Attribute Type No_of_instances No_of_attributes  Year  \n",
       "0    Categorical,Integer,Real            4177                8  1995  \n",
       "1         Categorical,Integer           48842               14  1996  \n",
       "2    Categorical,Integer,Real             798               38        \n",
       "3                 Categorical           37711              294  1998  \n",
       "4    Categorical,Integer,Real             452              279  1998  \n",
       "..                        ...             ...              ...   ...  \n",
       "583                                     12684               23  2020  \n",
       "584                      Real              48              321  2020  \n",
       "585                      Real             731             1068  2021  \n",
       "586                      Real             731             1068  2021  \n",
       "587                      Real             557                5  2021  \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the scraped data of uci machine learning repository\n",
    "print(\"UCI Machine Learning Repository :-\")\n",
    "uci_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
